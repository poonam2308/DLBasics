Key components of a transformer
1. Positional Encoding 
2. Self-attention Mechanism
3. Feed-Forward Neural Network
4. Layer Normalization
5. Multi-Head Attention
6. Encoder and Decoder Layers
7. Transformer Model
