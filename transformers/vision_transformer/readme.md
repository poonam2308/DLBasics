Key components of a vision transformer:
1. Patch Embedding: Flatten the image into patches and embed them.
2. Multi-Head Self-Attention: Attention mechanism.
3. Position Embeddings: Learn positional information to maintain the spatial relationship between patches.
4. Transformer Encoder: Multiple layers of multi-head self-attention and MLP
5. Classification Head: MLP to map the output to class probabilities 